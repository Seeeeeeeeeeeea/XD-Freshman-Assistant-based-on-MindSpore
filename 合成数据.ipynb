{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0958046-58f8-48c1-8770-01e1cf801036",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:04:25.151566Z",
     "start_time": "2025-09-20T07:04:25.148564Z"
    }
   },
   "outputs": [],
   "source": [
    "## 安装调用大模型的openai库和读pdf的pypdf库\n",
    "\n",
    "# !pip install openai pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d7426-92bc-486d-adc8-a0b142c80c39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:04:28.162488Z",
     "start_time": "2025-09-20T07:04:25.163145Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# API密钥\n",
    "API_TOKEN = \"\"  # 此处需要填写对应的api密钥\n",
    "MODEL_NAME = 'deepseek-v3'  # 选择要调用的模型名称\n",
    "\n",
    "# 请求URL\n",
    "BASE_URL = \"https://ng.115.zone/v1/\"\n",
    "\n",
    "# 创建一个LLM顾问实例对象\n",
    "llm_client = openai.OpenAI(api_key=API_TOKEN, base_url=BASE_URL)\n",
    "\n",
    "\n",
    "# 不要修改这个函数\n",
    "# 此函数的作用是发送LLM调用请求\n",
    "def llm_generate(messages: list[dict[str, str]], model_name=MODEL_NAME):\n",
    "    \"\"\"\n",
    "    发送OpenAI格式的大模型请求\n",
    "\n",
    "    参数:\n",
    "    - messages: 包含对话历史的字典列表，每个字典包含role和content键,role为user或assistant\n",
    "    - model_name: 要调用的模型名称\n",
    "\n",
    "    返回:\n",
    "    - 模型生成的回复内容\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 发送请求\n",
    "        response = llm_client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        # 返回模型生成的内容\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"请求发生错误: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eba025-22f6-4ad8-a0ba-49899be32965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:04:44.836029Z",
     "start_time": "2025-09-20T07:04:28.172809Z"
    }
   },
   "outputs": [],
   "source": [
    "# 简单尝试提问的问题\n",
    "question = \"西安电子科技大学新手入学实验班选拔考试考哪些科目，所占的比重如何\"\n",
    "\n",
    "print(\"## 问题：\", question)\n",
    "## 模型推理代码⬇️\n",
    "\n",
    "# 表明身份是用户user,内容是对应的问题\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "]\n",
    "\n",
    "# 调用llm_generate来生成内容并输出\n",
    "content = llm_generate(messages)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d647f80-0b3c-4d44-9682-b06e6fd88211",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 开始合成数据\n",
    "\n",
    "## 准备训练文件\n",
    "在data目录中我们寻找了若干文件对其文本进行读取操作，并且进行了简单的清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a120e830f063ca",
   "metadata": {},
   "source": [
    "### 将PDF政策文件提取为TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a60645845f144c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:04:46.461111Z",
     "start_time": "2025-09-20T07:04:44.847413Z"
    }
   },
   "outputs": [],
   "source": [
    "## 读取文件\n",
    "from pathlib import Path\n",
    "from docx import Document\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# 项目 data 文件夹路径\n",
    "data_folder = Path(\"data2\")\n",
    "output_file = \"output2.txt\"\n",
    "\n",
    "def read_docx(file_path):\n",
    "    \"\"\"读取 Word 文档内容\"\"\"\n",
    "    doc = Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    \"\"\"读取 PDF 文档内容\"\"\"\n",
    "    text = []\n",
    "    reader = PdfReader(file_path)\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:  # 避免空页导致 None\n",
    "            text.append(page_text)\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def main():\n",
    "    all_texts = []\n",
    "\n",
    "    # 遍历 data 文件夹下所有文件（非递归）\n",
    "    for file in sorted(data_folder.iterdir()):\n",
    "        if file.suffix.lower() == \".docx\":\n",
    "            print(f\"读取 Word 文件: {file.name}\")\n",
    "            all_texts.append(read_docx(file))\n",
    "        elif file.suffix.lower() == \".pdf\":\n",
    "            print(f\"读取 PDF 文件: {file.name}\")\n",
    "            all_texts.append(read_pdf(file))\n",
    "        else:\n",
    "            print(f\"跳过文件: {file.name}（非 docx/pdf）\")\n",
    "\n",
    "    # 保存到 output.txt\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\\n\".join(all_texts))\n",
    "\n",
    "    print(f\"所有文档内容已保存到 {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c240170-c490-4186-a885-8b4c747f051d",
   "metadata": {},
   "source": [
    "### 对txt文件数据进行简单处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540eb96710d44b53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:04:46.478152Z",
     "start_time": "2025-09-20T07:04:46.471955Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "input_file = \"output2.txt\"            # 输入文本文件\n",
    "output_file = \"output_cleaned2.txt\"   # 输出文本文件\n",
    "\n",
    "# 匹配页尾标注：中文破折号 — 数字 — 或 英文破折号 - 数字 -\n",
    "page_mark_pattern = re.compile(r\"^(?:—|-)\\s*\\d+\\s*(?:—|-)$\")\n",
    "\n",
    "def clean_text(file_path):\n",
    "    cleaned_text = []\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        # 去掉空行和首尾空格\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    for line in lines:\n",
    "        # 删除页尾标注\n",
    "        if page_mark_pattern.match(line):\n",
    "            continue\n",
    "        cleaned_text.append(line)\n",
    "\n",
    "    # 合并所有行为一行\n",
    "    return \"\".join(cleaned_text)\n",
    "\n",
    "def main():\n",
    "    cleaned_text = clean_text(input_file)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned_text)\n",
    "\n",
    "    print(f\"处理完成，结果已保存到 {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b4f187541b3c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:04:46.518800Z",
     "start_time": "2025-09-20T07:04:46.515368Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"output_cleaned2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "print(len(text), \"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf7677-7412-4d14-9783-21b3c3bc5552",
   "metadata": {},
   "source": [
    "## 构建一个随机抽取函数\n",
    "\n",
    "从导出的TXT中随机抽取一段文字（默认为抽取200字）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0157e4-d0c1-48a8-b647-a9841dd36854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:04:46.545678Z",
     "start_time": "2025-09-20T07:04:46.540678Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 一个阅读pdf文字并且转pdf的函数\n",
    "# 随机抽取文段，以此来让大模型根据这个文段进行提问\n",
    "\n",
    "def random_text_chunk(txt_path, chunk_length=800):\n",
    "    \"\"\"\n",
    "    从指定txt文件中随机读取一个长度为 chunk_length 个汉字的文本片段。\n",
    "    如果文本长度不足，则直接返回全文。\n",
    "    \"\"\"\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # 如果文本不够长，直接返回全部内容\n",
    "    if len(text) <= chunk_length:\n",
    "        return text\n",
    "\n",
    "    # 否则随机选取一个起始位置\n",
    "    start = random.randint(0, len(text) - chunk_length)\n",
    "    chunk = text[start:start + chunk_length]\n",
    "\n",
    "    return chunk\n",
    "\n",
    "\n",
    "text = random_text_chunk(\"output_cleaned2.txt\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8977cf-b2ac-4638-b1fb-5a89b3fe3137",
   "metadata": {},
   "source": [
    "## 让模型根据文本提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c54d6-3e6b-4e28-8581-65488af4a0ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:04:47.980391Z",
     "start_time": "2025-09-20T07:04:46.565193Z"
    }
   },
   "outputs": [],
   "source": [
    "## 用于提问题的提示词⬇️\n",
    "\n",
    "# 问答前提，可以自定义prompt文本\n",
    "\n",
    "prompt = \"根据下面的内容提取新生可能进行提问的重要信息，然后以新生的口吻提一个问题，注意该问题的答案必须在我提供的片段当中，注意你只返回问题，不要返回任何额外的信息或回答\"\n",
    "\n",
    "# llm是作为system角色回答的\n",
    "## 模型推理代码⬇️\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"user\", \"content\": \"以下是学校规定或者通知要求：\\n\\n\" + text},\n",
    "]\n",
    "content = llm_generate(messages)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110701b-6f65-4787-842f-a0cde886c57a",
   "metadata": {},
   "source": [
    "## 构建模型提问函数\n",
    "\n",
    "为了提取出文字，我们使用input长度来砍掉用于模型生成的文本段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af905650-d563-4592-aa7e-ead6c6077b64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:04:49.075179Z",
     "start_time": "2025-09-20T07:04:47.992461Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def question_model_generate(text):\n",
    "    \"\"\"\n",
    "    根据提供的PDF文本内容（如校规），调用模型生成一个以学生口吻提出的问题，\n",
    "    该问题的答案必须能从提供的文本中找到。\n",
    "\n",
    "    参数:\n",
    "    - text (str): 从PDF中提取的文本内容，作为生成问题的依据。\n",
    "\n",
    "    返回:\n",
    "    - str: 模型根据参考文本生成的学生提问。\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"请以西电新生的口吻提出一个自然合理，符合逻辑的问题，问题的答案必须能在我所提供的校规片段中找到。不要包含情景描述描述，例如自称我刚入学，对别人称呼学长等，只输出一个问题，不输出解释或答案。\"},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    content = llm_generate(messages)\n",
    "    return content\n",
    "\n",
    "\n",
    "# 测试函数是否正常工作\n",
    "question = question_model_generate(text)\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d2051-12b9-4bff-9d25-789a6f9c2670",
   "metadata": {},
   "source": [
    "## 构建模型回答函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fde2ab-c14c-4772-8a0b-6752eb985a88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:04:50.303634Z",
     "start_time": "2025-09-20T07:04:49.086396Z"
    }
   },
   "outputs": [],
   "source": [
    "# 根据提出的问题生成回答\n",
    "\n",
    "def answer_model_generate(question, text):\n",
    "    \"\"\"\n",
    "    根据用户提出的问题和提供的PDF文本内容（如校规），调用模型生成回答。\n",
    "\n",
    "    参数:\n",
    "    - question (str): 用户提出的问题。\n",
    "    - text (str): 从PDF中提取的文本内容，作为回答问题的依据。\n",
    "\n",
    "    返回:\n",
    "    - str: 模型根据问题和参考文本生成的回答。\n",
    "    \"\"\"\n",
    "    # 这里注意，要将参考文本输入到system prompt当中\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"你是西电新生百事通助手，请根据学生提出的单个问题，以及下面我提供的校规或公告内容，给出准确、完整的回答。回答必须严格依据校规内容，不加入校外信息。只输出回答内容，不输出提问或额外说明，生成的同时请你再次检查是否符合我的要求以及问题是否合理。\\n\\n\" + text},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "    content = llm_generate(messages)\n",
    "    return content\n",
    "\n",
    "\n",
    "# 测试函数是否正常工作\n",
    "answer = answer_model_generate(question, text)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237cba95-1afd-4a90-8a47-c5ec09ecf5a4",
   "metadata": {},
   "source": [
    "## 开始通过循环生成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae8686-cbe6-4749-8e52-8480b27af57a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:15:35.340091Z",
     "start_time": "2025-09-20T07:04:50.320792Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "question_num = 120  # 控制生成的数据数量\n",
    "\n",
    "GENERATE_QA_DATA = []\n",
    "for i in range(question_num):\n",
    "    print(f\"############# 生成第{i}个问题\")\n",
    "    # 随机抽取一段文本\n",
    "    text = random_text_chunk(\"output_cleaned2.txt\")\n",
    "    # print(f\"#### 抽取的文本\\n{text}\")\n",
    "    # 模型生成一个问题\n",
    "    question = question_model_generate(text)\n",
    "    print(\"### 问题：\")\n",
    "    print(question)\n",
    "    # 模型再给一个答案\n",
    "    answer = answer_model_generate(question, text)\n",
    "    print(\"### 回答：\")\n",
    "    print(answer)\n",
    "    time.sleep(1.5)\n",
    "    GENERATE_QA_DATA.append((question, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c3364d-b697-49d7-8066-c68a970bdbbb",
   "metadata": {},
   "source": [
    "## 以Alpaca数据集格式保存到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf7990-885a-4232-9fe6-42727a2ee5d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:15:35.412952Z",
     "start_time": "2025-09-20T07:15:35.405064Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "file_path = 'dataset.json'  # 输出文件路径\n",
    "\n",
    "# 用列表收集所有数据\n",
    "data_list = []\n",
    "\n",
    "for question, answer in GENERATE_QA_DATA:\n",
    "    alpaca_data = {\n",
    "        \"instruction\": question,\n",
    "        \"input\": \"\",\n",
    "        \"output\": str(answer)  # 保证 output 为字符串，避免 object 类型报错\n",
    "    }\n",
    "    data_list.append(alpaca_data)\n",
    "\n",
    "# 写入标准 JSON 数组文件，并美化格式\n",
    "with open(file_path, 'a', encoding='utf-8') as f:\n",
    "    json.dump(data_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"数据已保存至 {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c6319-dcae-4305-ae36-ce38c75945fb",
   "metadata": {},
   "source": [
    "## 接下来的作业本\n",
    "\n",
    "尝试修改上一讲的代码，来微调新的数据集"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.10.6",
   "language": "python",
   "name": "python-3.10.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
